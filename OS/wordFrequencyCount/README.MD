# 词频统计程序
Unix 环境下 C 语言编写的英文词频统计程序。分词的标准为连续的一串字母，例如: can't 被分成 can 和 t 两个单词

## 环境
+ gcc 5.4.0
+ GNU/Linux 4.4.0-96-generic Ubuntu 16.04.4 LTS x86_64
+ make 4.1

## 构建
以实验中的文件作为词频统计样例构建，键入命令：

    % make                  # 默认使用mmap字典树

若要测试程序的运行速度，可以以目录下的 essay_test.txt 为样例构建，键入命令：

    % make testhm           # 测试mmap哈希
    % make testtm           # 测试mmap字典树
    % make testt            # 测试字典树
    % make testh            # 测试哈希表

构建使用mmap进行文件读写的哈希版本，键入命令：

    % make hmmap

构建使用mmap进行文件读写的字典树版本，键入命令：

    % make tmmap

构建使用字典树的版本，键入命令：

    % make trie

构建使用哈希表的版本，键入命令：

    % make hash


## 运行
运行程序键入命令：

    % ./wfs


## 本地测试结果
+ 哈希和字典树两种算法运行时间差距很小，小文件字典树略快，大文件哈希略快
+ 读小文件时，mmap和普通read（scanf/getc）速度差距不大，mmap速度更稳定
+ 读大文件时，mmap速度更快


## 注意
+ 编译时需要使用 -O2 及以上的优化选项。原因是代码中有inline关键字修饰的函数，若不进行优化，编译器会找不到函数声明
+ 编译时需要使用 -std=c99 或其他兼容c99标准的选项
+ 预处理时可以使用 -D[macro[=defn]] 选项配置程序相关参数，如 -DMAX_LEN=40 可将单词最大长度设置为40个字符
+ 每种方法都使用了一些不可移植的操作提高效率
